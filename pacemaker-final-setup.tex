% Pacemaker Final Setup


\chapter{Pacemaker Final Setup}
\label{chap:pacemaker-final-setup}
This chapter explains how to setup Pacemaker to acomplish High Availability finally.

\section {Pacemaker Setup explained}
As explained in \textit{section \ref{sec:about-pacemaker} About Pacemaker} Pacemaker is High Availability resource manager, here we will explain how our setup pretends to manage our two servers resources. These instructions should only be performed on \textbf{primary} node.

These are the main settings we define in our configuration:
\begin{itemize}
  \item Setup deletes prior configuration.
  \item DRBD, Filesystem mount and Zimbra Server are setup to work in the same server as they work as in a team.
  \item System stickiness is changed so that Zimbra Server resource is not moved from where it's running to avoid Zimbra innecessary downtimes.
  \item System are forced to be started in the right order. The right order is: DRBD, Filesystem mount, and Zimbra Server.
  \item We disable stonith in order to simplify the setup.
  \item Primary server will be the prefered server where resources need to be run.
\end{itemize}

TODO: Check if we define stickiness somewhere else and make a reference here.

TODO: Add an explanation on stonith on a new Improvements chapter and make here a reference to it.


We make sure that \textit{/tmp/zimbrapacemaker.config} file contents are:
\begin{verbatim}
configure
erase
node primary
node secondary
# Activate failover
property no-quorum-policy=ignore
# Disable stonith
property stonith-enabled=false
# Resource stickiness
rsc_defaults resource-stickiness=100
# Public ip fail over check
primitive ClusterIP ocf:heartbeat:IPaddr2 \
params nic=eth0 ip=192.168.77.203 \
cidr_netmask=24 \
broadcast=192.168.77.255 \
op monitor interval=30s
# Configure zimbra resource
primitive ZimbraServer ocf:btactic:zimbra op \
monitor interval=2min timeout="40s" \
op start interval="0" timeout="360s" \
op stop interval="0" timeout="360s"
# Prefered location: primary node
location prefer-primary-node \
ZimbraServer 50: primary
# Define DRBD ZimbraData
primitive ZimbraData ocf:linbit:drbd params \
drbd_resource=zimbradata op monitor \
role=Master interval=60s op monitor \
role=Slave interval=50s \
op start role=Master interval="0" timeout="240" \
op start role=Slave interval="0" timeout="240" \
op stop role=Master interval="0" timeout="100" \
op stop role=Slave interval="0" timeout="100"
# Define DRBD ZimbraData Clone
ms ZimbraDataClone ZimbraData meta \
master-max=1 master-node-max=1 \
clone-max=2 clone-node-max=1 notify=true
# Define ZimbraFS so that zimbra can use it
primitive ZimbraFS ocf:heartbeat:Filesystem \
params device="/dev/drbd/by-res/zimbradata" \
directory="/opt" fstype="ext4" \
op start interval="0" timeout="60s" \
op stop interval="0" timeout="60s"
group MyZimbra ZimbraFS ZimbraServer


# Everything in the same host
colocation everything-together \
inf: MyZimbra \
ZimbraDataClone:Master ClusterIP

# Everything ordered
order everything-ordered \
inf: \
ClusterIP \
ZimbraDataClone:promote MyZimbra
commit
\end{verbatim}

In order to apply the configuration we will run:
\begin{verbatim}
crm < /tmp/zimbrapacemaker.config
\end{verbatim}
.



Pacemaker configuration is not trivial. The main document from which the configuration file was adapted and written was Clusters from Scratch (\cite{ClustersFromScratch}).

TODO: Check if we need an order for normal ip ifconfig or whatever it's called.

